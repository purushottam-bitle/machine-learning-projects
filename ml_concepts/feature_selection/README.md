# Feature Selection For Machine Learning

### Feature Selection

Feature selection is a process where you automatically select those features from your data that
contribute most to the prediction variable or output in which you are interested. Having irrelevant features in your data can decrease the accuracy of many models, especially linear algorithms like linear and logistic regression. Three benefits of performing feature selection before modeling your data are:

* **Reduces Overfitting:** Less redundant data means less opportunity to make decisions based on noise.
* **Improves Accuracy:** Less misleading data means modeling accuracy improves.
* **Reduces Training Time:** Less data means that algorithms train faster.

### Summary
In this tutorial we learned about feature selection for preparing machine learning data in Python
with scikit-learn. We learned about 4 different automatic feature selection techniques:

* Univariate Selection.
* Recursive Feature Elimination.
* Principle Component Analysis.
* Feature Importance.

